{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"data\"\n",
    "datatype_folder = \"csv\"\n",
    "data_folders = [\"buy\",\"communicate\",\"fun\",\"hope\",\"mother\",\"really\"]\n",
    "\n",
    "path = os.path.join(\"..\", root_folder, datatype_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample wise Normalizing\n",
    "----------------\n",
    "Various sample normalizing functions to try and decide upon. Convert the data into relative distance rather than absolute cooridnates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values are relative to the nose\n",
    "# left body y values are relative to the leftShoulder_y value\n",
    "# right body y values are relative to the rightShoulder_y value\n",
    "\n",
    "def normalize_sample(X):\n",
    "    x_num = X[:,0]\n",
    "    left_y = X[:,3]\n",
    "    right_y = X[:,5]\n",
    "    \n",
    "    for col in range(0, len(feature_list), 2):\n",
    "        X[:,col] = (X[:,col] - x_num)\n",
    "    \n",
    "    for col in range(3, len(feature_list), 4):\n",
    "        X[:,col] = (X[:,col] - left_y)\n",
    "    \n",
    "    for col in range(5, len(feature_list), 4):\n",
    "        X[:,col] = (X[:,col] - right_y)\n",
    "    \n",
    "    return X[:, [1,2,4,6,7,8,9,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values are relative to the nose_x\n",
    "# x values are relative to the nose_y\n",
    "\n",
    "def normalize_sample(X):    \n",
    "    x_num = X[:,0].copy()\n",
    "    y_num = X[:,1].copy()\n",
    "    \n",
    "    for col in range(0, len(feature_list), 2):\n",
    "        X[:,col] = X[:,col] - x_num\n",
    "    \n",
    "    for col in range(1, len(feature_list), 2):\n",
    "        X[:,col] = X[:,col] - y_num\n",
    "    \n",
    "    return X[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal normalization in terms of shoulder coordinates\n",
    "def normalize_sample(X):\n",
    "    x_denom = abs(X[:,2] - X[:,4]).copy()\n",
    "    y_denom = abs(X[:,3] - X[:,5]).copy()\n",
    "    x_num = X[:,0].copy()\n",
    "    y_num = X[:,1].copy()\n",
    "    \n",
    "    for col in range(6, len(feature_list), 2):\n",
    "        X[:,col] = (X[:,col] - x_num)/x_denom\n",
    "    \n",
    "    for col in range(7, len(feature_list), 2):\n",
    "        X[:,col] = (X[:,col] - y_num)/y_denom\n",
    "    \n",
    "    return X[:,6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting only useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\"nose_x\", \"nose_y\", \"leftShoulder_x\", \"leftShoulder_y\", \"rightShoulder_x\", \"rightShoulder_y\", \"leftElbow_x\", \"leftElbow_y\", \"rightElbow_x\", \"rightElbow_y\", \"leftWrist_x\", \"leftWrist_y\", \"rightWrist_x\", \"rightWrist_y\"]\n",
    "label_dict = {'buy':0,'communicate':1,'fun':2,'hope':3,'mother':4,'really':5}\n",
    "X = []\n",
    "Y = []\n",
    "for sign in data_folders:\n",
    "    for file in os.listdir(os.path.join(path, sign)):\n",
    "        file_path = os.path.join(path, sign, file)\n",
    "        \n",
    "        df = pd.read_csv(file_path)[feature_list]\n",
    "        sample = df.to_numpy()\n",
    "        sample = normalize_sample(sample)\n",
    "        # sample = scaling_sample(sample)\n",
    "        \n",
    "        X.append(sample)\n",
    "        Y.append(label_dict[sign])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataframe of same size\n",
    "---------------\n",
    "Adding content to videos to make them of equal size. Reducing the size of larger videos would remove important information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All videos now of length: 250\n",
      "X shape : (415, 250, 12) \n",
      "Y Shape : (415,)\n"
     ]
    }
   ],
   "source": [
    "def extend_data(X, kind=\"zeros\"):\n",
    "    def zeros(sample, diff, num_features):\n",
    "        return np.full(shape=(diff, num_features), fill_value=0)\n",
    "    \n",
    "    def means(sample, diff, num_features):\n",
    "        mean_array = np.reshape(np.mean(sample, axis=0), (1,num_features))\n",
    "        return np.repeat(mean_array, diff, axis=0)\n",
    "    \n",
    "    def copies(sample, diff, num_features):\n",
    "        last_array = np.reshape(sample[-1], (1,num_features))\n",
    "        return np.repeat(last_array, diff, axis=0)\n",
    "    \n",
    "    num_features = X[0].shape[-1]\n",
    "    max_timeframes = max([len(sign) for sign in X])\n",
    "    max_timeframes = max_timeframes + 50 - (max_timeframes%50)\n",
    "    print(\"All videos now of length: {}\".format(max_timeframes))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        diff = max_timeframes - len(X[i])\n",
    "        switcher = {\"zeros\": zeros(X[i], diff, num_features), \n",
    "                   \"means\": means(X[i], diff, num_features), \n",
    "                   \"copies\": copies(X[i], diff, num_features)}\n",
    "        append_array = switcher[kind] \n",
    "        X[i] = np.append(X[i], append_array, axis=0)\n",
    "        \n",
    "    return X\n",
    "\n",
    "X = extend_data(X, kind=\"zeros\")\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "num_samples, num_timeframes, num_features = X.shape\n",
    "print(\"X shape : {} \\nY Shape : {}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Noramlized list data\n",
    "-----------------\n",
    "saving the entire normalized data and the label so that we dont run it again and again. We are only saving features that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"..\", \"IPD\", \"normalized_x.npy\"), X)\n",
    "np.save(os.path.join(\"..\", \"IPD\", \"normalized_y.npy\"), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples : (332, 250, 12) \n",
      "Testing Samples : (83, 250, 12)\n",
      "Training Labels : (332,) \n",
      "Testing Labels : (83,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(\"Training samples : {} \\nTesting Samples : {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"Training Labels : {} \\nTesting Labels : {}\".format(Y_train.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X, kind=\"minmax\", feature_range=(-1,1)):\n",
    "    scaling_dict = { \"standard\": StandardScaler(), \n",
    "                \"minmax\": MinMaxScaler(feature_range=feature_range)}\n",
    "    scaler = scaling_dict[kind]\n",
    "    scaler.fit(X)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples : (332, 250, 12) \n",
      "Testing Samples : (83, 250, 12)\n",
      "Training Labels : (332,) \n",
      "Testing Labels : (83,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],-1))\n",
    "X_test = X_test.reshape((X_test.shape[0],-1))\n",
    "\n",
    "scaler = scaling(X_train, kind=\"minmax\", feature_range=(-1,1))\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape((-1,num_timeframes,num_features))\n",
    "X_test = X_test.reshape((-1,num_timeframes,num_features))\n",
    "print(\"Training samples : {} \\nTesting Samples : {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"Training Labels : {} \\nTesting Labels : {}\".format(Y_train.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save scaling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(os.path.join(\"..\", \"IPD\", \"scaler.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"..\", \"IPD\", \"x_train.npy\"), X_train)\n",
    "np.save(os.path.join(\"..\", \"IPD\", \"x_test.npy\"), X_test)\n",
    "np.save(os.path.join(\"..\", \"IPD\", \"y_train.npy\"), Y_train)\n",
    "np.save(os.path.join(\"..\", \"IPD\", \"y_test.npy\"), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
